{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 当我们谈论旅行的时候，我们在谈论什么？\n",
    "\n",
    "- 知乎爬虫，关键词“旅行，旅游，景点”全部问题及回答\n",
    "- 小红书IP被限制登录了，遂转战知乎\n",
    "- 爬虫使用脚本MediaCrawler，语义情感分析使用SnowNLP（中文模型），停用词使用中文停用词表、哈工大停用词表、机器智能实验室停用词库\n",
    "- 交互使用dash app，不确定是否适配网页版\n",
    "- plotly rendering设置为notebook，网页端需要更改\n",
    "- 所有图表颜色样式default，需要更改\n",
    "- 目前进展： data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('vegafusion')\n",
    "import numpy as np\n",
    "from snownlp import SnowNLP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import plotly.express as px\n",
    "from plotly import io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import jieba\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "comments_df = pd.read_json('data/comments.json', encoding='utf-8')\n",
    "contents_df = pd.read_json('data/contents.json', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subselect\n",
    "comments_df[['content', 'sub_comment_count', 'publish_time', 'content_id']]\n",
    "contents_df = contents_df[['content_id', 'content_type', 'content_text', 'title', 'desc', 'created_time', 'voteup_count', 'comment_count']]\n",
    "\n",
    "# drop na\n",
    "comments_df = comments_df.dropna(subset=['content'])\n",
    "contents_df = contents_df.dropna(subset=['content_text', 'desc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to date format\n",
    "comments_df['publish_date'] = pd.to_datetime(comments_df['publish_time']).dt.date\n",
    "contents_df['created_date'] = pd.to_datetime(contents_df['created_time']).dt.date\n",
    "\n",
    "comments_df['year'] = pd.to_datetime(comments_df['publish_time']).dt.year\n",
    "contents_df['year'] = pd.to_datetime(contents_df['created_time']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# app layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Heatmap: Content & Comment\"),\n",
    "    dcc.Dropdown(\n",
    "        id=\"dataset-dropdown\",\n",
    "        options=[\n",
    "            {\"label\": \"Comment Data\", \"value\": \"comments\"},\n",
    "            {\"label\": \"Content Data\", \"value\": \"contents\"}\n",
    "        ],\n",
    "        value=\"comments\",\n",
    "        placeholder=\"Select Dataset\"\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id=\"year-dropdown\",\n",
    "        placeholder=\"Select Year\"\n",
    "    ),\n",
    "    dcc.Graph(id=\"heatmap\"),\n",
    "])\n",
    "\n",
    "# call: updated year selection\n",
    "@app.callback(\n",
    "    Output(\"year-dropdown\", \"options\"),\n",
    "    Output(\"year-dropdown\", \"value\"),\n",
    "    Input(\"dataset-dropdown\", \"value\")\n",
    ")\n",
    "def update_year_options(selected_dataset):\n",
    "    if selected_dataset == \"comments\":\n",
    "        years = sorted(comments_df['year'].unique())\n",
    "    else:\n",
    "        years = sorted(contents_df['year'].unique())\n",
    "    options = [{\"label\": str(year), \"value\": year} for year in years]\n",
    "    return options, years[0]\n",
    "\n",
    "# call: update heatmap\n",
    "@app.callback(\n",
    "    Output(\"heatmap\", \"figure\"),\n",
    "    Input(\"dataset-dropdown\", \"value\"),\n",
    "    Input(\"year-dropdown\", \"value\")\n",
    ")\n",
    "def update_heatmap(selected_dataset, selected_year):\n",
    "    if selected_dataset == \"comments\":\n",
    "        filtered_df = comments_df[comments_df['year'] == selected_year]\n",
    "        fig = px.density_heatmap(\n",
    "            filtered_df,\n",
    "            x=\"publish_date\",\n",
    "            y=\"sub_comment_count\",\n",
    "            labels={'publish_date': 'Date', 'sub_comment_count': 'Comment COunt'},\n",
    "            nbinsx=365,\n",
    "            title=f\"Comment Distribution by Date - {selected_year}\"\n",
    "        )\n",
    "    else:\n",
    "        filtered_df = contents_df[contents_df['year'] == selected_year]\n",
    "        fig = px.density_heatmap(\n",
    "            filtered_df,\n",
    "            x=\"created_date\",\n",
    "            y='voteup_count',\n",
    "            labels={'created_date': 'Date', 'VoteUp Count': 'Likes'},\n",
    "            nbinsx=365,\n",
    "            title=f\"Content Distribution by Date - {selected_year}\"\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(tickformat=\"%b-%d\", title=\"Date\"),\n",
    "        yaxis_title=\"Value\",\n",
    "        title_x=0.5,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# run app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Emotion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snownlp emotion func\n",
    "def analyze_sentiment(text):\n",
    "    if text.strip():\n",
    "        s = SnowNLP(text)\n",
    "        return s.sentiments\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title desc analysis\n",
    "contents_df['desc_sentiment'] = contents_df['desc'].apply(analyze_sentiment)\n",
    "\n",
    "# content text analysis\n",
    "# dropna\n",
    "contents_df['content_text'] = contents_df['content_text'].fillna('')\n",
    "\n",
    "contents_df['sentiment'] = contents_df['content_text'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_df[['content_id', 'title', 'desc_sentiment','content_text', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment analysis\n",
    "comments_df['sentiment'] = comments_df['content'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df[['content', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Content & Comment Emotion Analysis\"),\n",
    "    \n",
    "    # year selection dropdown\n",
    "    dcc.Dropdown(\n",
    "        id=\"year-selector\",\n",
    "        options=[{'label': str(year), 'value': year} for year in contents_df['year'].unique()],\n",
    "        value=contents_df['year'].min(),  # default min year\n",
    "        multi=False\n",
    "    ),\n",
    "    \n",
    "    dcc.Graph(id='content-sentiment-chart'),\n",
    "\n",
    "    dcc.Graph(id='comment-sentiment-chart'),\n",
    "])\n",
    "\n",
    "\n",
    "# update by year\n",
    "@app.callback(\n",
    "    [Output('content-sentiment-chart', 'figure'),\n",
    "     Output('comment-sentiment-chart', 'figure')],\n",
    "    [Input('year-selector', 'value')]\n",
    ")\n",
    "def update_charts(selected_year):\n",
    "    content_year_df = contents_df[contents_df['year'] == selected_year]\n",
    "    comments_year_df = comments_df[comments_df['year'] == selected_year]\n",
    "\n",
    "    # emotion recategory\n",
    "    content_year_df['sentiment_category'] = content_year_df['desc_sentiment'].apply(lambda x: 'Positive' if x > 0.5 else 'Negative')\n",
    "    \n",
    "    #content\n",
    "    content_sentiment_fig = px.histogram(\n",
    "        content_year_df,\n",
    "        x='desc_sentiment',\n",
    "        color='sentiment_category',\n",
    "        title=f\"Content Emotion Analysis ({selected_year})\",\n",
    "        labels={'desc_sentiment': 'Emotion Value'},\n",
    "        marginal=\"box\"\n",
    "    )\n",
    "\n",
    "    # comment\n",
    "    comment_sentiment_fig = px.scatter(\n",
    "        comments_year_df,\n",
    "        x='sentiment',\n",
    "        y='content_id',\n",
    "        color='sentiment',\n",
    "        title=f\"Comment Emotion Analysis ({selected_year})\",\n",
    "        labels={'sentiment': 'Emotion Value', 'content_id': 'Content ID'},\n",
    "        hover_data=['content_id', 'publish_date', 'sentiment']\n",
    "    )\n",
    "\n",
    "    return content_sentiment_fig, comment_sentiment_fig\n",
    "\n",
    "\n",
    "# launch\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "# category func\n",
    "def categorize_sentiment(df, sentiment_column):\n",
    "    df['sentiment_category'] = pd.cut(df[sentiment_column], bins=[-float('inf'), 0.3, 0.7, float('inf')],\n",
    "                                      labels=['Negative', 'Neutral', 'Positive'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content text\n",
    "contents_df = categorize_sentiment(contents_df, 'sentiment') \n",
    "contents_text_hist = px.histogram(\n",
    "    contents_df,\n",
    "    x='sentiment_category',\n",
    "    color='sentiment_category',\n",
    "    title=\"Content Text Emotion Distribution Histogram\",\n",
    "    labels={'sentiment_category': 'Emotion Category'},\n",
    "    marginal=\"box\"\n",
    ")\n",
    "\n",
    "# content desc\n",
    "contents_df = categorize_sentiment(contents_df, 'desc_sentiment')\n",
    "contents_desc_hist = px.histogram(\n",
    "    contents_df,\n",
    "    x='sentiment_category',\n",
    "    color='sentiment_category',\n",
    "    title=\"Content Description Emotion Distribution Histogram\",\n",
    "    labels={'sentiment_category': 'Emotion Category'},\n",
    "    marginal=\"box\"\n",
    ")\n",
    "\n",
    "# comment\n",
    "comments_df = categorize_sentiment(comments_df, 'sentiment')\n",
    "comments_hist = px.histogram(\n",
    "    comments_df,\n",
    "    x='sentiment_category',\n",
    "    color='sentiment_category',\n",
    "    title=\"Comment Emotion Distribution Histogram\",\n",
    "    labels={'sentiment_category': 'Emotion Category'},\n",
    "    marginal=\"box\"\n",
    ")\n",
    "\n",
    "contents_text_hist.show()\n",
    "contents_desc_hist.show()\n",
    "comments_hist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud\n",
    "\n",
    "# func\n",
    "# stopwords\n",
    "def cut_words_without_stopwords(text, stopwords):\n",
    "    words = jieba.cut(text)\n",
    "    return [word for word in words if word not in stopwords and len(word) > 1]\n",
    "\n",
    "def load_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        stopwords = set(f.read().splitlines())\n",
    "    return stopwords\n",
    "\n",
    "def generate_wordcloud(text_data, title, stopwords):\n",
    "    # word split (CN)\n",
    "    text = \" \".join(cut_words_without_stopwords(\" \".join(text_data), stopwords))\n",
    "    \n",
    "    wordcloud = WordCloud(\n",
    "        font_path=\"CNFont.ttf\", \n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color=\"white\",\n",
    "        max_words=100,\n",
    "        min_font_size=10\n",
    "    ).generate(text)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "stopwords = load_stopwords(\"cn_stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_content = contents_df[contents_df['desc_sentiment'] > 0.5]\n",
    "negative_content = contents_df[contents_df['desc_sentiment'] <= 0.5]\n",
    "\n",
    "positive_comment = comments_df[comments_df['sentiment'] > 0.5]\n",
    "negative_comment = comments_df[comments_df['sentiment'] <= 0.5]\n",
    "\n",
    "# wordcloud generate\n",
    "generate_wordcloud(positive_content['desc'], \"Positive Content Title Description Wordcloud\", stopwords)\n",
    "generate_wordcloud(positive_content['content_text'], \"Positive Content Text Wordcloud\", stopwords)\n",
    "generate_wordcloud(positive_comment['content'], \"Positive Comment Wordcloud\", stopwords)\n",
    "\n",
    "generate_wordcloud(negative_content['desc'], \"Negative Content Title Description Wordcloud\", stopwords)\n",
    "generate_wordcloud(negative_content['content_text'], \"Negative Content Text Wordcloud\", stopwords)\n",
    "generate_wordcloud(negative_comment['content'], \"Negative Comment Wordcloud\", stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: desc & comment\n",
    "texts = contents_df['desc'].dropna().tolist() + comments_df['content'].dropna().tolist()\n",
    "stopwords = load_stopwords(\"cn_stopwords.txt\")\n",
    "chinese_digits = [\"一\", \"二\", \"三\", \"四\", \"五\", \"六\", \"七\", \"八\", \"九\", \"十\",\"百\",\"千\",\"万\"]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # remove EN\n",
    "    text = re.sub(r'[a-zA-Z]+', '', text)\n",
    "    words = jieba.cut(text)\n",
    "    # remove CN digits\n",
    "    words = [word for word in words if not any(digit in word for digit in chinese_digits)]\n",
    "    return \" \".join(word for word in words if word not in stopwords and len(word) > 1)\n",
    "\n",
    "texts = [preprocess_text(word) for word in texts]\n",
    "\n",
    "# initialize TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# TF-IDF feature matrix\n",
    "text_features = tfidf.fit_transform(texts)\n",
    "\n",
    "# feature words\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "print(feature_names[:30])\n",
    "\n",
    "# k\n",
    "sil_scores = []\n",
    "k_values = range(2, 10)\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(text_features)\n",
    "    sil_scores.append(silhouette_score(text_features, labels))\n",
    "\n",
    "# visualization\n",
    "plt.plot(k_values, sil_scores, marker='o')\n",
    "plt.title(\"Silhouette Scores for Different K\")\n",
    "plt.xlabel(\"Number of Clusters (K)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.show()\n",
    "\n",
    "# best k\n",
    "best_k = k_values[sil_scores.index(max(sil_scores))]\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "clusters = kmeans.fit_predict(text_features)\n",
    "\n",
    "clustered_texts = pd.DataFrame({'text': texts, 'cluster': clusters})\n",
    "clustered_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_features = pca.fit_transform(text_features.toarray())\n",
    "reduced_cluster_df = pd.DataFrame(reduced_features, columns=[\"PC1\", \"PC2\"])\n",
    "reduced_cluster_df[\"cluster\"] = clusters\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=reduced_cluster_df, x=\"PC1\", y=\"PC2\", hue=\"cluster\", palette=\"viridis\")\n",
    "plt.title(\"Cluster Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       content_id content_type  \\\n",
       "0     2983182867       answer   \n",
       "1     3554122723       answer   \n",
       "2      106211663       answer   \n",
       "3      633685987       answer   \n",
       "4       31530201       answer   \n",
       "...          ...          ...   \n",
       "1130   163740657       answer   \n",
       "1131  2978932676       answer   \n",
       "1132   136047390      article   \n",
       "1133  2850330205       answer   \n",
       "1134   580250300       answer   \n",
       "\n",
       "                                           content_text  \\\n",
       "0     旅游就是累的。。。全世界旅游都是累的。。。因为旅游和度假是两个东西。。。举个例子好了，巴黎，...   \n",
       "1     有个朋友，女孩，朋友圈全是旅行。仿佛她世界中只有风景，美照、美食和礼物。突然有一天，她的朋友...   \n",
       "2     1.我就是那种家庭条件一般，还喜欢频繁到处旅游，还喜欢发微博晒的大学生。2.我旅游没用多少家...   \n",
       "3     本回答发布于2019.3.27，最新更新于2020.5.21五一假期我又去大西北了，由于时间...   \n",
       "4     真的能，而且改变很大。 旅行让人变得谦逊、包容、乐观、坚韧，表现在外就是一种见过大世面的气质...   \n",
       "...                                                 ...   \n",
       "1130  先说明一下贵州的整体地理情况，贵州整个景点的串联会比较分散，因为它并不像旁边云南等地可以昆明...   \n",
       "1131  特种兵式旅游，不仅仅是累这么简单。睡 3 小时+日均 9 万步+8 个景点+花费少，想要完成...   \n",
       "1132  安徽最有名的6大景点，必去旅行目的地,网友强烈推荐的好去处哦！    安徽地跨长江、淮河南北...   \n",
       "1133  现在五一也过去了，来宁波玩过的难道一个都没有？这么惨吗？来玩过的可以点评了，别被干沉默了啊。...   \n",
       "1134  独立寒秋，湘江北去，橘子洲头。看万山红遍，层林尽染；漫江碧透，百舸争流。鹰击长空，鱼翔浅底，...   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                      为什么国人的旅游方式普遍特别累？   \n",
       "1                                      如何看待朋友圈里一直在旅行的人？   \n",
       "2                                       如何看待大学生频繁高消费旅行？   \n",
       "3                                你们去过哪些地方旅行？其中哪里让你感觉很值？   \n",
       "4                                           旅行真的能使人改变吗？   \n",
       "...                                                 ...   \n",
       "1130                                       贵州旅游景点有哪些推荐？   \n",
       "1131  一天打卡 8 个景点、只睡 3 小时，大学生「特种兵式」旅游爆火，如何看待此现象？你倾向哪种...   \n",
       "1132                    安徽最有名的6大景点，必去旅行目的地,网友强烈推荐的好去处哦！   \n",
       "1133                                       宁波有哪些坑爹旅游景点？   \n",
       "1134                       「橘子洲」是一个什么景点，有哪些吸引人的地方和特色景观？   \n",
       "\n",
       "                                                   desc        created_time  \\\n",
       "0     可能问题没有问清楚，起因是前两天跟我父母去海南旅游，觉得特别的累。感觉根本不是去放松身心的，... 2023-04-14 02:35:18   \n",
       "1     十年前的成功学书籍很少提到“旅行”二字， 而近十年的成功学书籍中， “不管有没有钱，每年至少... 2024-07-07 04:19:20   \n",
       "2     嗯哼，我也是逢寒暑假就远途旅行的。～～～～～～～～～～～～～～～～～～～～～感谢各位答主的回... 2016-06-16 01:17:32   \n",
       "3                                                       2019-03-27 04:03:58   \n",
       "4     许多旅行作家会列出富有传奇色彩的、轶事一样的证据，来说明旅行是一件可以改变人生的事情。比如伊... 2014-10-08 01:46:21   \n",
       "...                                                 ...                 ...   \n",
       "1130  好喝的杨梅汤。而刚新建的荔波古镇也可以逛逛。 小七孔整个景区很大，全程约十几公里，所以步行难... 2017-05-02 10:11:42   \n",
       "1131  近日，“特种兵式旅游”“军训式旅游”“大学生军训式旅游”等词条在众多社交媒体上成为热门话题，... 2023-04-11 10:22:15   \n",
       "1132  最后希望宏村人能继续保留徽州人的习俗和纯朴。 2、九华山风景区 九华山 ，是首批国家重点风景... 2020-04-24 12:49:57   \n",
       "1133              本问题已被收录至 撰写你的知乎「城市手册」 活动，更多活动详情请点击查看。 2023-01-18 00:18:33   \n",
       "1134  本问题被收录至活动「十万个是什么」中。活动时间：2019/01/21 - 2019/02/2... 2019-01-23 09:23:24   \n",
       "\n",
       "      voteup_count  comment_count created_date  year  desc_sentiment  \\\n",
       "0            14529            500   2023-04-14  2023        0.315599   \n",
       "1             2621            446   2024-07-07  2024        0.999956   \n",
       "2              851            213   2016-06-16  2016        0.203454   \n",
       "3            14680           1312   2019-03-27  2019             NaN   \n",
       "4             4030            420   2014-10-08  2014        1.000000   \n",
       "...            ...            ...          ...   ...             ...   \n",
       "1130           249             25   2017-05-02  2017        0.991741   \n",
       "1131           948            247   2023-04-11  2023        1.000000   \n",
       "1132            62              4   2020-04-24  2020        0.999963   \n",
       "1133           196            125   2023-01-18  2023        0.118214   \n",
       "1134           214              5   2019-01-23  2019        0.999790   \n",
       "\n",
       "      sentiment  sub_comment_count  \n",
       "0      0.999998             1231.0  \n",
       "1      1.000000              196.0  \n",
       "2      1.000000               24.0  \n",
       "3      1.000000              282.0  \n",
       "4      1.000000               35.0  \n",
       "...         ...                ...  \n",
       "1130   1.000000                4.0  \n",
       "1131   0.100638              404.0  \n",
       "1132   1.000000                NaN  \n",
       "1133   0.000000               32.0  \n",
       "1134   1.000000                1.0  \n",
       "\n",
       "[1135 rows x 13 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sub comment count sum by content id\n",
    "sub_comment_sum = comments_df.groupby('content_id')['sub_comment_count'].sum().reset_index()\n",
    "contents_df = contents_df.merge(sub_comment_sum, on='content_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input feature: voteup count, comment count, sub comment count; target: desc_sentiment\n",
    "features = ['voteup_count', 'comment_count', 'sub_comment_count']\n",
    "target = 'desc_sentiment'\n",
    "\n",
    "data = contents_df[features + [target]].dropna()\n",
    "\n",
    "# split into training 80%/test 20%\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomforest\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.050538825012269986\n",
      "R² Score: 0.5797429164686416\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R² Score: {r2}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc22f03017d74bace6978a999c4f44a07b7dbf76a5e22e671257b5ce8b5d48e0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
